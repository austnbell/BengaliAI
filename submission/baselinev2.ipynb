{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/model3/weighted_model.pt\n",
      "/kaggle/input/bengaliai-cv19/train.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/class_map.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_3.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_0.parquet\n",
      "/kaggle/input/bengaliai-cv19/test.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_0.parquet\n",
      "/kaggle/input/bengaliai-cv19/sample_submission.csv\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_3.parquet\n",
      "/kaggle/input/densenet121/densenet121-a639ec97.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import albumentations as A\n",
    "import pyarrow\n",
    "import cv2\n",
    "import itertools\n",
    "\n",
    "import six\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential\n",
    "from torchvision import models\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Parameters\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "SIZE = 128\n",
    "\n",
    "model_name = \"model3/weighted_model.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Define our dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper\n",
    "class DatasetMixin(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Returns an example or a sequence of examples.\"\"\"\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        if isinstance(index, slice):\n",
    "            current, stop, step = index.indices(len(self))\n",
    "            return [self.get_example_wrapper(i) for i in\n",
    "                    six.moves.range(current, stop, step)]\n",
    "        elif isinstance(index, list) or isinstance(index, np.ndarray):\n",
    "            return [self.get_example_wrapper(i) for i in index]\n",
    "        else:\n",
    "            return self.get_example_wrapper(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of data points.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_example_wrapper(self, i):\n",
    "        \"\"\"Wrapper of `get_example`, to apply `transform` if necessary\"\"\"\n",
    "        example = self.get_example(i)\n",
    "        \n",
    "        if self.transform:\n",
    "            \n",
    "            if self.labels:\n",
    "                example_img = self.transform(image = example[0])['image']\n",
    "            \n",
    "                return example_img, example[1]\n",
    "        \n",
    "            # doing this terrible code, because Idk how to make the super take a none type\n",
    "            example_img = self.transform(image = example)['image']\n",
    "            return example\n",
    "\n",
    "    def get_example(self, i):\n",
    "        \"\"\"Returns the i-th example.\n",
    "\n",
    "        Implementations should override it. It should raise :class:`IndexError`\n",
    "        if the index is invalid.\n",
    "\n",
    "        Args:\n",
    "            i (int): The index of the example.\n",
    "\n",
    "        Returns:\n",
    "            The i-th example.\n",
    "\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# actual class\n",
    "class BengaliAIDataset(DatasetMixin):\n",
    "    def __init__(self, images, labels=None, transform=None, indices=None):\n",
    "        super(BengaliAIDataset, self).__init__(transform=transform)\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        if indices is None:\n",
    "            indices = np.arange(len(images))\n",
    "        self.indices = indices\n",
    "        self.train = labels is not None\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return length of this dataset\"\"\"\n",
    "        return len(self.indices)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        \"\"\"Return i-th data\"\"\"\n",
    "        i = self.indices[i]\n",
    "        x = self.images[i]\n",
    "        \n",
    "        # for future Affine transformation\n",
    "        x = x.astype(np.float32)\n",
    "        if self.train:\n",
    "            y = self.labels[i]\n",
    "            return x, y\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Load Images\n",
    "###################################################################\n",
    "\n",
    "# during submission, we load via parquet\n",
    "def prepare_image(datadir, data_type, submission=False, indices=[0, 1, 2, 3]):\n",
    "\n",
    "    assert data_type in ['train', 'test']\n",
    "    if submission:\n",
    "        image_df_list = [pd.read_parquet(datadir + f'/{data_type}_image_data_{i}.parquet')\n",
    "                         for i in indices]\n",
    "    else:\n",
    "        image_df_list = [pd.read_feather(datadir + f'/{data_type}_image_data_{i}.feather')\n",
    "                         for i in indices]\n",
    "\n",
    "    print('image_df_list', len(image_df_list))\n",
    "    HEIGHT = 137\n",
    "    WIDTH = 236\n",
    "    \n",
    "    #somehow the original input is inverted\n",
    "    images = [df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH) for df in image_df_list]\n",
    "    \n",
    "    del image_df_list\n",
    "    gc.collect()\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    return images\n",
    "\n",
    "# convert our graphemes to labels\n",
    "def convertGrapheme(train):\n",
    "    graphemes = train.grapheme.unique()\n",
    "    num_graphemes = len(graphemes)\n",
    "    grapheme_dict = dict(zip(graphemes, range(num_graphemes)))\n",
    "    \n",
    "    return train.replace({\"grapheme\":grapheme_dict})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Crop and Resize our images\n",
    "###################################################################\n",
    "# bounding box\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def crop_resize(img0, size=SIZE, pad=16):\n",
    "    #crop a box around pixels large than the threshold \n",
    "    #some images contain line at the sides\n",
    "    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "    \n",
    "    #cropping may cut too much, so we need to add it back\n",
    "    xmin = xmin - 13 if (xmin > 13) else 0\n",
    "    ymin = ymin - 10 if (ymin > 10) else 0\n",
    "    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n",
    "    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n",
    "    img = img0[ymin:ymax,xmin:xmax]\n",
    "    \n",
    "    #remove low intensity pixels as noise\n",
    "    img[img < 28] = 0\n",
    "    lx, ly = xmax-xmin,ymax-ymin\n",
    "    l = max(lx,ly) + pad\n",
    "    \n",
    "    #make sure that the aspect ratio is kept in rescaling\n",
    "    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "    #img = cv2.normalize(img+255, None, dtype=cv2.CV_32F)\n",
    "    return cv2.resize(img,(size,size))\n",
    "\n",
    "def crop_char_image(image, threshold=40./255.):\n",
    "    assert image.ndim == 2\n",
    "    is_black = image > threshold\n",
    "\n",
    "    is_black_vertical = np.sum(is_black, axis=0) > 0\n",
    "    is_black_horizontal = np.sum(is_black, axis=1) > 0\n",
    "    left = np.argmax(is_black_horizontal)\n",
    "    right = np.argmax(is_black_horizontal[::-1])\n",
    "    top = np.argmax(is_black_vertical)\n",
    "    bottom = np.argmax(is_black_vertical[::-1])\n",
    "    height, width = image.shape\n",
    "    cropped_image = image[left:height - right, top:width - bottom]\n",
    "    return cropped_image\n",
    "\n",
    "def resize(image, size=(128, 128)):\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "# run for all images \n",
    "def runCropRsz(images):\n",
    "    crop_rsz_img = []\n",
    "    for idx in range(len(images)):\n",
    "        img = images[idx]\n",
    "        img = crop_char_image(img, threshold = 40./255.)\n",
    "        img = resize(img)\n",
    "        \n",
    "        # add to our stored list\n",
    "        crop_rsz_img.append(img)\n",
    "\n",
    "    crop_rsz_img = np.array(crop_rsz_img)\n",
    "    \n",
    "    return crop_rsz_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################################################################\n",
    "# Data Augmentations Pipeline\n",
    "###################################################################\n",
    "# define our augmentations\n",
    "def augPipeline(P = .5):\n",
    "    return A.Compose([\n",
    "        A.IAAAdditiveGaussianNoise(p=.3),\n",
    "        A.OneOf([\n",
    "            A.MedianBlur(blur_limit=3, p=0.4),\n",
    "            A.Blur(blur_limit=1, p=0.4),\n",
    "        ], p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=.1, scale_limit=0.0, rotate_limit=15, p=.75),\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=.4),\n",
    "            A.GridDistortion(p=.2),\n",
    "            A.IAAPiecewiseAffine(p=.5),\n",
    "        ], p=.33)], p=P)\n",
    "    \n",
    "    \n",
    "# generates weights by class to pass into a sampler during training\n",
    "def genWeightTensor(column, train):\n",
    "    class_counts = train[column].value_counts()\n",
    "    weight = 1 / class_counts\n",
    "    return torch.tensor([weight[t] for t in train[column]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Main Function to Generate and Load the dataset\n",
    "###################################################################\n",
    "def genDataset(indices, inputdir, data_type = \"train\", train = None):\n",
    "    assert data_type in ['train', 'test']    \n",
    "    \n",
    "    submission = False if data_type == \"train\" else True\n",
    "    indices = indices # which train files to load \n",
    "    images = prepare_image(inputdir, data_type=data_type, submission=submission, indices=indices)\n",
    "    #images = images[:int(round(len(images)*.5,0))]\n",
    "    print(\"~~Loaded Images~~\")\n",
    "    \n",
    "    \n",
    "    # run our crop and resize functions\n",
    "    crop_rsz_img = runCropRsz(images)\n",
    "    print(\"~~Standardized Images~~\")\n",
    "\n",
    "    p = .5 if data_type == \"train\" else 0\n",
    "    # init augmentation pipeline\n",
    "    augmentation = augPipeline(p)\n",
    "\n",
    "    # generate our dataset\n",
    "    if data_type == \"train\":\n",
    "        train_labels = train[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "        dataset = BengaliAIDataset(crop_rsz_img, labels = train_labels[:len(crop_rsz_img)], transform = augmentation) \n",
    "        \n",
    "        return dataset, crop_rsz_img\n",
    "    else:\n",
    "        dataset = BengaliAIDataset(crop_rsz_img, transform = augmentation)\n",
    "        del images, crop_rsz_img\n",
    "        gc.collect()\n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Our Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just a skip connection (very important if we have a ton of layers)\n",
    "# if we want to concatenate input with the output of the linear layer + activation\n",
    "def residual_add(lhs, rhs):\n",
    "    lhs_ch, rhs_ch = lhs.shape[1], rhs.shape[1]\n",
    "    if lhs_ch < rhs_ch:\n",
    "        out = lhs + rhs[:, :lhs_ch]\n",
    "    elif lhs_ch > rhs_ch:\n",
    "        out = torch.cat([lhs[:, :rhs_ch] + rhs, lhs[:, rhs_ch:]], dim=1)\n",
    "    else:\n",
    "        out = lhs + rhs\n",
    "    return out\n",
    "\n",
    "\n",
    "# block of linear functions - this is a single layer and can be changed \n",
    "# change this if we want to change our functions\n",
    "class LinearBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 use_bn=True, activation=F.relu, dropout_ratio=-1, residual=False,):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        if use_bn:\n",
    "            self.bn = nn.BatchNorm1d(out_features)\n",
    "        if dropout_ratio > 0.:\n",
    "            self.dropout = nn.Dropout(p=dropout_ratio)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.activation = activation\n",
    "        self.use_bn = use_bn\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.residual = residual\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = self.linear(x)\n",
    "        if self.use_bn:\n",
    "            h = self.bn(h)\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "        if self.residual:\n",
    "            h = residual_add(h, x)\n",
    "        if self.dropout_ratio > 0:\n",
    "            h = self.dropout(h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TORCH_HOME'] = '/kaggle/input/densenet121/' #setting the environment variable\n",
    "\n",
    "\n",
    "# core underlying model \n",
    "class densenet(nn.Module):\n",
    "    def __init__(self,in_channels = 1,out_dim=10, use_bn=True):\n",
    "        super(densenet, self).__init__()\n",
    "        \n",
    "        # convolution -- I do not know the point is for this\n",
    "        # I will ignore this for now\n",
    "        self.conv0 = nn.Sequential(nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=1, bias=True))\n",
    "        \n",
    "        # pretrained model \n",
    "        self.base_model = models.densenet121(pretrained=False)\n",
    "       \n",
    "        inch = self.base_model.classifier.in_features\n",
    "        \n",
    "        # should move to train parameters\n",
    "        activation = F.leaky_relu\n",
    "        hdim = 512\n",
    "        n_total_graphemes = 1285\n",
    "        \n",
    "        self.lin1 = LinearBlock(inch, hdim, use_bn=use_bn, activation=activation, residual=False)\n",
    "        \n",
    "        # predicts the whole grapheme \n",
    "        # the out dimension is now the number of classes for whole grapheme prediction\n",
    "        self.lin2 = LinearBlock(hdim, n_total_graphemes, use_bn=use_bn, activation=None, residual=False)\n",
    "        \n",
    "        # the input is the concatenation of lin1 and lin 2\n",
    "        # input = h_dim + out_dim_lin2; output = out_dim\n",
    "        self.lin3 = LinearBlock(hdim + n_total_graphemes, out_dim, use_bn=use_bn, activation=None, residual=False)\n",
    "        \n",
    "        #self.lin_layers = Sequential(lin1, lin2, lin3)\n",
    "\n",
    "    # the core forward pass\n",
    "    def forward(self, x):\n",
    "        h = self.conv0(x)\n",
    "        h = self.base_model.features(h) # I want to make sure that this is correct\n",
    "        h = torch.sum(h, dim=(-1, -2)) # pooling function \n",
    "        \n",
    "        # take out of loop and write out manually\n",
    "        h1 = self.lin1(h)\n",
    "        h_grapheme = self.lin2(h1)\n",
    "        out = self.lin3(torch.cat((h1, h_grapheme), 1))\n",
    "       \n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliClassifier(nn.Module):\n",
    "    def __init__(self, predictor, n_grapheme=168, n_vowel=11, n_consonant=7,data_type='train'):\n",
    "        super(BengaliClassifier, self).__init__()\n",
    "        self.n_grapheme = n_grapheme\n",
    "        self.n_vowel = n_vowel\n",
    "        self.n_consonant = n_consonant\n",
    "        self.n_total_class = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        self.predictor = predictor\n",
    "        self.data_type = data_type\n",
    "\n",
    "        self.metrics_keys = [\n",
    "            'loss', 'loss_grapheme', 'loss_vowel', 'loss_consonant',\n",
    "            'acc_grapheme', 'acc_vowel', 'acc_consonant', 'weighted_recall']\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        pred = self.predictor(x)\n",
    "        \n",
    "        if isinstance(pred, tuple):\n",
    "            assert len(pred) == 3\n",
    "            preds = pred\n",
    "        else:\n",
    "            assert pred.shape[1] == self.n_total_class\n",
    "            preds = torch.split(pred, [self.n_grapheme, self.n_vowel, self.n_consonant], dim=1)\n",
    "           \n",
    "        # compute our individual losses and generate single loss value\n",
    "        # TODO: test other loss functions\n",
    "        if self.data_type == 'train':\n",
    "            loss_grapheme = F.cross_entropy(preds[0], y[:, 0])\n",
    "            loss_vowel = F.cross_entropy(preds[1], y[:, 1])\n",
    "            loss_consonant = F.cross_entropy(preds[2], y[:, 2])\n",
    "            loss = loss_grapheme + loss_vowel + loss_consonant\n",
    "        \n",
    "        # metric summary\n",
    "            metrics = {\n",
    "                'loss': loss.item(),\n",
    "                'loss_grapheme': loss_grapheme.item(),\n",
    "                'loss_vowel': loss_vowel.item(),\n",
    "                'loss_consonant': loss_consonant.item(),\n",
    "                'acc_grapheme': accuracy(preds[0], y[:, 0]),\n",
    "                'acc_vowel': accuracy(preds[1], y[:, 1]),\n",
    "                'acc_consonant': accuracy(preds[2], y[:, 2])\n",
    "                #'weighted_recall': macro_recall(preds, y) # will figure this out later\n",
    "            }\n",
    "        \n",
    "            return loss, metrics, pred\n",
    "        else:\n",
    "            return preds\n",
    "\n",
    "    # run our prediction\n",
    "    def calc(self, data_loader):\n",
    "        device: torch.device = next(self.parameters()).device\n",
    "        self.eval()\n",
    "        output_list = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(data_loader):\n",
    "                \n",
    "                batch = batch.to(device)\n",
    "                pred = self.predictor(batch)\n",
    "                output_list.append(pred)\n",
    "        output = torch.cat(output_list, dim=0)\n",
    "        preds = torch.split(output, [self.n_grapheme, self.n_vowel, self.n_consonant], dim=1)\n",
    "        return preds\n",
    "\n",
    "    # return probabilities\n",
    "    def predict_proba(self, data_loader):\n",
    "        preds = self.calc(data_loader)\n",
    "        return [F.softmax(p, dim=1) for p in preds]\n",
    "\n",
    "    # return actual predictions\n",
    "    def predict(self, data_loader):\n",
    "        preds = self.calc(data_loader)\n",
    "        pred_labels = [torch.argmax(p, dim=1) for p in preds]\n",
    "        return pred_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our paths and parameters\n",
    "inputdir = \"/kaggle/input/bengaliai-cv19\"\n",
    "\n",
    "# Parameters\n",
    "data_type = 'test'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=128\n",
    "\n",
    "n_grapheme = 168\n",
    "n_vowel = 11\n",
    "n_consonant = 7\n",
    "n_total = n_grapheme + n_vowel + n_consonant\n",
    "\n",
    "bs = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BengaliClassifier(\n",
       "  (predictor): densenet(\n",
       "    (conv0): Sequential(\n",
       "      (0): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (base_model): DenseNet(\n",
       "      (features): Sequential(\n",
       "        (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu0): ReLU(inplace=True)\n",
       "        (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (denseblock1): _DenseBlock(\n",
       "          (denselayer1): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer2): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer3): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer4): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer5): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer6): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (transition1): _Transition(\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (denseblock2): _DenseBlock(\n",
       "          (denselayer1): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer2): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer3): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer4): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer5): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer6): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer7): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer8): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer9): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer10): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer11): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer12): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (transition2): _Transition(\n",
       "          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (denseblock3): _DenseBlock(\n",
       "          (denselayer1): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer2): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer3): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer4): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer5): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer6): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer7): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer8): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer9): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer10): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer11): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer12): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer13): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer14): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer15): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer16): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer17): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer18): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer19): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer20): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer21): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer22): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer23): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer24): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (transition3): _Transition(\n",
       "          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (denseblock4): _DenseBlock(\n",
       "          (denselayer1): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer2): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer3): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer4): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer5): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer6): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer7): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer8): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer9): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer10): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer11): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer12): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer13): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer14): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer15): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer16): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "    )\n",
       "    (lin1): LinearBlock(\n",
       "      (linear): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (lin2): LinearBlock(\n",
       "      (linear): Linear(in_features=512, out_features=1285, bias=True)\n",
       "      (bn): BatchNorm1d(1285, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (lin3): LinearBlock(\n",
       "      (linear): Linear(in_features=1797, out_features=186, bias=True)\n",
       "      (bn): BatchNorm1d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "predictor = densenet(in_channels=1, out_dim=n_total).to(device)\n",
    "state_dict =torch.load('/kaggle/input/'+ model_name)\n",
    "#predictor=load_my_state_dict(model, state_dict)\n",
    "\n",
    "classifier = BengaliClassifier(predictor,data_type='test')\n",
    "classifier.load_state_dict(state_dict)\n",
    "classifier = classifier.to(device)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.read_csv(inputdir+'/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 44.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 33.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# run \n",
    "predictor.eval()\n",
    "classifier.eval()\n",
    "\n",
    "grapheme_list = []\n",
    "vowel_list = []\n",
    "consonant_list = []\n",
    "\n",
    "for i in range(4):\n",
    "    indices = [i] # stream datasets to reduce memory\n",
    "    submission = True\n",
    "    dataset = genDataset(indices, inputdir, data_type = \"test\") # generates the dataset class\n",
    "\n",
    "    # push to data loader\n",
    "    test_loader = DataLoader(dataset, batch_size=bs, shuffle = False)\n",
    "\n",
    "    del dataset\n",
    "    gc.collect()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            grapheme,vowel,consonant = classifier(inputs.unsqueeze(1).float())\n",
    "\n",
    "            grapheme_list += list(grapheme.argmax(1).cpu().detach().numpy())\n",
    "            vowel_list += list(vowel.argmax(1).cpu().detach().numpy())\n",
    "            consonant_list += list(consonant.argmax(1).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###submission\n",
    "#submission = pd.read_csv(inputdir + '/sample_submission.csv')\n",
    "#submission.target = np.hstack(np.asarray(predictions).T)\n",
    "#submission\n",
    "#submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 27700.41it/s]\n"
     ]
    }
   ],
   "source": [
    "row_id = []\n",
    "target = []\n",
    "for i in tqdm(range(len(grapheme_list))):\n",
    "    row_id += [f'Test_{i}_grapheme_root', f'Test_{i}_vowel_diacritic',\n",
    "               f'Test_{i}_consonant_diacritic']\n",
    "    target += [grapheme_list[i], vowel_list[i], consonant_list[i]]\n",
    "submission_df = pd.DataFrame({'row_id': row_id, 'target': target})\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
