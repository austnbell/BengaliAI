{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/seresnext2/SeResNext.pt\n",
      "/kaggle/input/bengaliai-cv19/train.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/class_map.csv\n",
      "/kaggle/input/bengaliai-cv19/train_multi_diacritics.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_3.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_0.parquet\n",
      "/kaggle/input/bengaliai-cv19/test.csv\n",
      "/kaggle/input/bengaliai-cv19/class_map_corrected.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_0.parquet\n",
      "/kaggle/input/bengaliai-cv19/sample_submission.csv\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_3.parquet\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/setup.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/setup.cfg\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/PKG-INFO\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/README.md\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/__init__.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/version.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/utils.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/datasets/__init__.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/datasets/voc.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/datasets/utils.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/xception.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/nasnet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/wideresnet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/__init__.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/inceptionv4.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/dpn.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/cafferesnet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/torchvision_models.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/pnasnet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/nasnet_mobile.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/polynet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/senet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/inceptionresnetv2.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/fbresnet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/vggm.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/resnext.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/bninception.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/utils.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/resnext_features/__init__.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/resnext_features/resnext101_64x4d_features.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/resnext_features/resnext101_32x4d_features.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/setup.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/setup.cfg\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/PKG-INFO\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/README.md\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/__init__.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/version.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/utils.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/datasets/__init__.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/datasets/voc.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/datasets/utils.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/xception.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/nasnet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/wideresnet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/__init__.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/inceptionv4.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/dpn.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/cafferesnet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/torchvision_models.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/pnasnet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/nasnet_mobile.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/polynet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/senet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/inceptionresnetv2.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/fbresnet.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/vggm.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/resnext.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/bninception.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/utils.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/resnext_features/__init__.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/resnext_features/resnext101_64x4d_features.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels/models/resnext_features/resnext101_32x4d_features.py\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels.egg-info/SOURCES.txt\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels.egg-info/top_level.txt\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels.egg-info/dependency_links.txt\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels.egg-info/requires.txt\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/pretrainedmodels.egg-info/PKG-INFO\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels.egg-info/SOURCES.txt\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels.egg-info/top_level.txt\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels.egg-info/dependency_links.txt\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels.egg-info/requires.txt\n",
      "/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels.egg-info/PKG-INFO\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import albumentations as A\n",
    "import pyarrow\n",
    "import cv2\n",
    "import itertools\n",
    "\n",
    "import six\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential\n",
    "from torchvision import models\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/ > /dev/null # no output\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Parameters\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "SIZE = 128\n",
    "\n",
    "model_name = \"seresnext2/SeResNext.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Define our dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper\n",
    "class DatasetMixin(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Returns an example or a sequence of examples.\"\"\"\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        if isinstance(index, slice):\n",
    "            current, stop, step = index.indices(len(self))\n",
    "            return [self.get_example_wrapper(i) for i in\n",
    "                    six.moves.range(current, stop, step)]\n",
    "        elif isinstance(index, list) or isinstance(index, np.ndarray):\n",
    "            return [self.get_example_wrapper(i) for i in index]\n",
    "        else:\n",
    "            return self.get_example_wrapper(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of data points.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_example_wrapper(self, i):\n",
    "        \"\"\"Wrapper of `get_example`, to apply `transform` if necessary\"\"\"\n",
    "        example = self.get_example(i)\n",
    "        \n",
    "        if self.transform:\n",
    "            \n",
    "            if self.labels:\n",
    "                example_img = self.transform(image = example[0])['image']\n",
    "            \n",
    "                return example_img, example[1]\n",
    "        \n",
    "            # doing this terrible code, because Idk how to make the super take a none type\n",
    "            example_img = self.transform(image = example)['image']\n",
    "            return example\n",
    "\n",
    "    def get_example(self, i):\n",
    "        \"\"\"Returns the i-th example.\n",
    "\n",
    "        Implementations should override it. It should raise :class:`IndexError`\n",
    "        if the index is invalid.\n",
    "\n",
    "        Args:\n",
    "            i (int): The index of the example.\n",
    "\n",
    "        Returns:\n",
    "            The i-th example.\n",
    "\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# actual class\n",
    "class BengaliAIDataset(DatasetMixin):\n",
    "    def __init__(self, images, labels=None, transform=None, indices=None):\n",
    "        super(BengaliAIDataset, self).__init__(transform=transform)\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        if indices is None:\n",
    "            indices = np.arange(len(images))\n",
    "        self.indices = indices\n",
    "        self.train = labels is not None\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return length of this dataset\"\"\"\n",
    "        return len(self.indices)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        \"\"\"Return i-th data\"\"\"\n",
    "        i = self.indices[i]\n",
    "        x = self.images[i]\n",
    "        \n",
    "        # for future Affine transformation\n",
    "        x = x.astype(np.float32)\n",
    "        if self.train:\n",
    "            y = self.labels[i]\n",
    "            return x, y\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Load Images\n",
    "###################################################################\n",
    "\n",
    "# during submission, we load via parquet\n",
    "def prepare_image(datadir, data_type, submission=False, indices=[0, 1, 2, 3]):\n",
    "\n",
    "    assert data_type in ['train', 'test']\n",
    "    if submission:\n",
    "        image_df_list = [pd.read_parquet(datadir + f'/{data_type}_image_data_{i}.parquet')\n",
    "                         for i in indices]\n",
    "    else:\n",
    "        image_df_list = [pd.read_feather(datadir + f'/{data_type}_image_data_{i}.feather')\n",
    "                         for i in indices]\n",
    "\n",
    "    print('image_df_list', len(image_df_list))\n",
    "    HEIGHT = 137\n",
    "    WIDTH = 236\n",
    "    \n",
    "    #somehow the original input is inverted\n",
    "    images = [df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH) for df in image_df_list]\n",
    "    \n",
    "    del image_df_list\n",
    "    gc.collect()\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    return images\n",
    "\n",
    "# convert our graphemes to labels\n",
    "def convertGrapheme(train):\n",
    "    graphemes = train.grapheme.unique()\n",
    "    num_graphemes = len(graphemes)\n",
    "    grapheme_dict = dict(zip(graphemes, range(num_graphemes)))\n",
    "    \n",
    "    return train.replace({\"grapheme\":grapheme_dict})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Crop and Resize our images\n",
    "###################################################################\n",
    "# bounding box\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def crop_resize(img0, size=SIZE, pad=16):\n",
    "    #crop a box around pixels large than the threshold \n",
    "    #some images contain line at the sides\n",
    "    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "    \n",
    "    #cropping may cut too much, so we need to add it back\n",
    "    xmin = xmin - 13 if (xmin > 13) else 0\n",
    "    ymin = ymin - 10 if (ymin > 10) else 0\n",
    "    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n",
    "    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n",
    "    img = img0[ymin:ymax,xmin:xmax]\n",
    "    \n",
    "    #remove low intensity pixels as noise\n",
    "    img[img < 28] = 0\n",
    "    lx, ly = xmax-xmin,ymax-ymin\n",
    "    l = max(lx,ly) + pad\n",
    "    \n",
    "    #make sure that the aspect ratio is kept in rescaling\n",
    "    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "    #img = cv2.normalize(img+255, None, dtype=cv2.CV_32F)\n",
    "    return cv2.resize(img,(size,size))\n",
    "\n",
    "\n",
    "# run for all images \n",
    "def runCropRsz(images):\n",
    "    crop_rsz_img = []\n",
    "    for idx in range(len(images)):\n",
    "        img0 = (255 - images[idx]).astype(np.float32)\n",
    "        # normalize each image by its max val\n",
    "        img = (img0*(255.0/img0.max())).astype(np.float32)\n",
    "        img = crop_resize(img)\n",
    "        \n",
    "        # add to our stored list\n",
    "        crop_rsz_img.append(img)\n",
    "\n",
    "    crop_rsz_img = np.array(crop_rsz_img)\n",
    "    \n",
    "    return crop_rsz_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################################################################\n",
    "# Data Augmentations Pipeline\n",
    "###################################################################\n",
    "# define our augmentations\n",
    "def augPipeline(P = .75):\n",
    "    return A.Compose([\n",
    "        A.IAAAdditiveGaussianNoise(p=.6),\n",
    "        A.OneOf([\n",
    "            A.MedianBlur(blur_limit=3, p=0.6),\n",
    "            A.Blur(blur_limit=1, p=0.6),\n",
    "        ], p=0.5),\n",
    "        A.ShiftScaleRotate( rotate_limit=15, p=.85), # leave shift and scale as defaults\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=.6),\n",
    "            A.GridDistortion(p=.4),\n",
    "            A.IAAPiecewiseAffine(p=.75),\n",
    "        ], p=.5)],\n",
    "        p=P)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Main Function to Generate and Load the dataset\n",
    "###################################################################\n",
    "def genDataset(indices, inputdir, split_num, split_index):\n",
    "    assert data_type in ['train', 'test']    \n",
    "    \n",
    "    submission = False if data_type == \"train\" else True\n",
    "    indices = indices # which train files to load \n",
    "    images = prepare_image(inputdir, data_type=data_type, submission=submission, indices=indices)\n",
    "    images = np.array_split(images, split_num)[split_index]\n",
    "    # lets split the indices\n",
    "    \n",
    "    print(\"~~Loaded Images~~\")\n",
    "    \n",
    "    \n",
    "    # run our crop and resize functions\n",
    "    crop_rsz_img = runCropRsz(images)\n",
    "    print(\"~~Standardized Images~~\")\n",
    "\n",
    "    p = .5 if data_type == \"train\" else 0\n",
    "    # init augmentation pipeline\n",
    "    augmentation = augPipeline(p)\n",
    "\n",
    "    # generate our dataset\n",
    "    dataset = BengaliAIDataset(crop_rsz_img, transform = augmentation)\n",
    "    del images, crop_rsz_img\n",
    "    gc.collect()\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Our Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just a skip connection (very important if we have a ton of layers)\n",
    "# if we want to concatenate input with the output of the linear layer + activation\n",
    "def residual_add(lhs, rhs):\n",
    "    lhs_ch, rhs_ch = lhs.shape[1], rhs.shape[1]\n",
    "    if lhs_ch < rhs_ch:\n",
    "        out = lhs + rhs[:, :lhs_ch]\n",
    "    elif lhs_ch > rhs_ch:\n",
    "        out = torch.cat([lhs[:, :rhs_ch] + rhs, lhs[:, rhs_ch:]], dim=1)\n",
    "    else:\n",
    "        out = lhs + rhs\n",
    "    return out\n",
    "\n",
    "\n",
    "# block of linear functions - this is a single layer and can be changed \n",
    "# change this if we want to change our functions\n",
    "class LinearBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 use_bn=True, activation=F.relu, dropout_ratio=-1, residual=False,):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        if use_bn:\n",
    "            self.bn = nn.BatchNorm1d(out_features)\n",
    "        if dropout_ratio > 0.:\n",
    "            self.dropout = nn.Dropout(p=dropout_ratio)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.activation = activation\n",
    "        self.use_bn = use_bn\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.residual = residual\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = self.linear(x)\n",
    "        if self.use_bn:\n",
    "            h = self.bn(h)\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "        if self.residual:\n",
    "            h = residual_add(h, x)\n",
    "        if self.dropout_ratio > 0:\n",
    "            h = self.dropout(h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#os.environ['TORCH_HOME'] = '/kaggle/input/densenet121/' #setting the environment variable\n",
    "\n",
    "\n",
    "# core underlying model \n",
    "class seresnext(nn.Module):\n",
    "    def __init__(self,in_channels = 1,out_dim=10, use_bn=True):\n",
    "        super(seresnext, self).__init__()\n",
    "        \n",
    "        # convolution -- I do not know the point is for this\n",
    "        # I will ignore this for now\n",
    "        self.conv0 = nn.Sequential(nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=1, bias=True))\n",
    "        \n",
    "        # pretrained model \n",
    "        self.base_model = pretrainedmodels.__dict__['se_resnext101_32x4d'](pretrained=None)\n",
    "        inch = self.base_model.last_linear.in_features\n",
    "        \n",
    "        # should move to train parameters\n",
    "        activation = F.leaky_relu\n",
    "        hdim = 512\n",
    "        n_total_graphemes = 1285\n",
    "        \n",
    "        self.lin1 = LinearBlock(inch, hdim, use_bn=use_bn, activation=activation, residual=False)\n",
    "        \n",
    "        # predicts the whole grapheme \n",
    "        # the out dimension is now the number of classes for whole grapheme prediction\n",
    "        self.lin2 = LinearBlock(hdim, n_total_graphemes, use_bn=use_bn, activation=None, residual=False)\n",
    "        \n",
    "        # the input is the concatenation of lin1 and lin 2\n",
    "        # input = h_dim + out_dim_lin2; output = out_dim\n",
    "        self.lin3 = LinearBlock(hdim + n_total_graphemes, out_dim, use_bn=False, activation=None, residual=False)\n",
    "        \n",
    "      \n",
    "    # the core forward pass\n",
    "    def forward(self, x):\n",
    "        h = self.conv0(x)\n",
    "        h = self.base_model.features(h) # I want to make sure that this is correct\n",
    "        h = torch.sum(h, dim=(-1, -2)) # pooling function \n",
    "        \n",
    "        # take out of loop and write out manually\n",
    "        h1 = self.lin1(h)\n",
    "        h_grapheme = self.lin2(h1)\n",
    "        out = self.lin3(torch.cat((h1, h_grapheme), 1))\n",
    "       \n",
    "        \n",
    "        return out, h_grapheme\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliClassifier(nn.Module):\n",
    "    def __init__(self, predictor, n_grapheme=168, n_vowel=11, n_consonant=7,data_type='train'):\n",
    "        super(BengaliClassifier, self).__init__()\n",
    "        self.n_grapheme = n_grapheme\n",
    "        self.n_vowel = n_vowel\n",
    "        self.n_consonant = n_consonant\n",
    "        self.n_total_class = self.n_grapheme + self.n_vowel + self.n_consonant\n",
    "        self.predictor = predictor\n",
    "        self.data_type = data_type\n",
    "\n",
    "        self.metrics_keys = [\n",
    "            'loss', 'loss_grapheme', 'loss_vowel', 'loss_consonant',\n",
    "            'acc_grapheme', 'acc_vowel', 'acc_consonant', 'weighted_recall']\n",
    "\n",
    "    def forward(self, x, whole_grapheme_loss=False, y=None):\n",
    "        pred = self.predictor(x)\n",
    "        \n",
    "        # if i return the whole grapheme prediction then split the tuple\n",
    "        if isinstance(pred, tuple):\n",
    "            assert len(pred) == 2\n",
    "            pred_grapheme = pred[1]\n",
    "            pred = pred[0]\n",
    "       \n",
    "        assert pred.shape[1] == self.n_total_class\n",
    "        preds = torch.split(pred, [self.n_grapheme, self.n_vowel, self.n_consonant], dim=1)\n",
    "        \n",
    "        # compute our individual losses and generate single loss value\n",
    "        # TODO: test other loss functions\n",
    "        if self.data_type == 'train':\n",
    "            # change cross entropy to focal loss\n",
    "            #loss_grapheme = FocalLoss(preds[0], y[:, 0])\n",
    "            #loss_vowel = FocalLoss(preds[1], y[:, 1])\n",
    "            #loss_consonant = FocalLoss(preds[2], y[:, 2])\n",
    "            loss_grapheme = F.cross_entropy(preds[0], y[:, 0])\n",
    "            loss_vowel = F.cross_entropy(preds[1], y[:, 1])\n",
    "            loss_consonant = F.cross_entropy(preds[2], y[:, 2])\n",
    "            \n",
    "            loss = loss_grapheme + loss_vowel + loss_consonant\n",
    "            if whole_grapheme_loss:\n",
    "                loss += F.cross_entropy(pred_grapheme, y[:, 3])\n",
    "        \n",
    "        # metric summary\n",
    "            metrics = {\n",
    "                'loss': loss.item(),\n",
    "                'loss_grapheme': loss_grapheme.item(),\n",
    "                'loss_vowel': loss_vowel.item(),\n",
    "                'loss_consonant': loss_consonant.item(),\n",
    "                'acc_grapheme': accuracy(preds[0], y[:, 0]),\n",
    "                'acc_vowel': accuracy(preds[1], y[:, 1]),\n",
    "                'acc_consonant': accuracy(preds[2], y[:, 2]),\n",
    "                'weighted_recall': macro_recall(pred, y) # will figure this out later\n",
    "            }\n",
    "        \n",
    "            return loss, metrics, pred\n",
    "        else:\n",
    "            return preds\n",
    "\n",
    "    # run our prediction\n",
    "    def calc(self, data_loader):\n",
    "        device: torch.device = next(self.parameters()).device\n",
    "        self.eval()\n",
    "        output_list = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(data_loader):\n",
    "                \n",
    "                batch = batch.to(device)\n",
    "                pred = self.predictor(batch)\n",
    "                output_list.append(pred)\n",
    "        output = torch.cat(output_list, dim=0)\n",
    "        preds = torch.split(output, [self.n_grapheme, self.n_vowel, self.n_consonant], dim=1)\n",
    "        return preds\n",
    "\n",
    "    # return probabilities\n",
    "    def predict_proba(self, data_loader):\n",
    "        preds = self.calc(data_loader)\n",
    "        return [F.softmax(p, dim=1) for p in preds]\n",
    "\n",
    "    # return actual predictions\n",
    "    def predict(self, data_loader):\n",
    "        preds = self.calc(data_loader)\n",
    "        pred_labels = [torch.argmax(p, dim=1) for p in preds]\n",
    "        return pred_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our paths and parameters\n",
    "inputdir = \"/kaggle/input/bengaliai-cv19\"\n",
    "\n",
    "# Parameters\n",
    "data_type = 'test'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_grapheme = 168\n",
    "n_vowel = 11\n",
    "n_consonant = 7\n",
    "n_total = n_grapheme + n_vowel + n_consonant\n",
    "\n",
    "bs = 32\n",
    "split_num = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BengaliClassifier(\n",
       "  (predictor): seresnext(\n",
       "    (conv0): Sequential(\n",
       "      (0): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (base_model): SENet(\n",
       "      (layer0): Sequential(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      )\n",
       "      (layer1): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (3): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (3): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (4): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (5): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (6): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (7): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (8): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (9): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (10): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (11): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (12): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (13): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (14): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (15): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (16): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (17): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (18): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (19): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (20): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (21): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (22): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (2): SEResNeXtBottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se_module): SEModule(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "      (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    )\n",
       "    (lin1): LinearBlock(\n",
       "      (linear): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (lin2): LinearBlock(\n",
       "      (linear): Linear(in_features=512, out_features=1285, bias=True)\n",
       "      (bn): BatchNorm1d(1285, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (lin3): LinearBlock(\n",
       "      (linear): Linear(in_features=1797, out_features=186, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "predictor = seresnext(in_channels=1, out_dim=n_total).to(device)\n",
    "state_dict =torch.load('/kaggle/input/'+ model_name)\n",
    "#predictor=load_my_state_dict(model, state_dict)\n",
    "\n",
    "classifier = BengaliClassifier(predictor,data_type='test')\n",
    "classifier.load_state_dict(state_dict)\n",
    "classifier = classifier.to(device)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 20.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 20.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 21.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 12.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 19.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 21.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 21.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 21.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 22.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_df_list 1\n",
      "~~Loaded Images~~\n",
      "~~Standardized Images~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00, 21.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# run \n",
    "predictor.eval()\n",
    "classifier.eval()\n",
    "\n",
    "grapheme_list = []\n",
    "vowel_list = []\n",
    "consonant_list = []\n",
    "\n",
    "for i in range(4):\n",
    "    indices = [i] # stream datasets to reduce memory\n",
    "    submission = True\n",
    "    \n",
    "    for j in range(split_num):\n",
    "        # we then only handle 1/3rd of the data at a time\n",
    "        dataset = genDataset(indices, inputdir, split_num = split_num, split_index = j) # generates the dataset class\n",
    "\n",
    "        # push to data loader\n",
    "        test_loader = DataLoader(dataset, batch_size=bs, shuffle = False)\n",
    "\n",
    "        del dataset\n",
    "        gc.collect()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs in tqdm(test_loader):\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                grapheme,vowel,consonant = classifier(inputs.unsqueeze(1).float())\n",
    "\n",
    "                grapheme_list += list(grapheme.argmax(1).cpu().detach().numpy())\n",
    "                vowel_list += list(vowel.argmax(1).cpu().detach().numpy())\n",
    "                consonant_list += list(consonant.argmax(1).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###submission\n",
    "#submission = pd.read_csv(inputdir + '/sample_submission.csv')\n",
    "#submission.target = np.hstack(np.asarray(predictions).T)\n",
    "#submission\n",
    "#submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 12/12 [00:00<00:00, 28942.87it/s]\n"
     ]
    }
   ],
   "source": [
    "row_id = []\n",
    "target = []\n",
    "for i in tqdm(range(len(grapheme_list))):\n",
    "    row_id += [f'Test_{i}_grapheme_root', f'Test_{i}_vowel_diacritic',\n",
    "               f'Test_{i}_consonant_diacritic']\n",
    "    target += [grapheme_list[i], vowel_list[i], consonant_list[i]]\n",
    "submission_df = pd.DataFrame({'row_id': row_id, 'target': target})\n",
    "#submission_df\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
